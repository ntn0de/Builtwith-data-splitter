{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc6031ae-2908-4110-89b7-f4dabcee6954",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87e59f51-9a1f-403f-ab7d-febc72be1a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata0 = pd.read_csv(\"BigCommerce-US.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d51b1be-9b3a-47a0-aff6-9331d854daf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Domain                       Location on Site  \\\n",
      "0                       1ink.com                               1ink.com   \n",
      "1                 22mods4all.com                         22mods4all.com   \n",
      "2                      4moms.com  shop.4moms.com;staging-shop.4moms.com   \n",
      "3          backcountryaccess.com           secure.backcountryaccess.com   \n",
      "4             badgleymischka.com                     badgleymischka.com   \n",
      "...                          ...                                    ...   \n",
      "39701      torresomarjewelry.com                  torresomarjewelry.com   \n",
      "39702         toshioclothing.com                     toshioclothing.com   \n",
      "39703        toshiocreations.com                    toshiocreations.com   \n",
      "39704  totalnutritionflorida.com              totalnutritionflorida.com   \n",
      "39705       totalpartscanada.com                   totalpartscanada.com   \n",
      "\n",
      "      Tech Spend USD Sales Revenue USD                    Company  \\\n",
      "0               $500            $57879   Paragon Solution Network   \n",
      "1               $500            $49054             22Mods4All Inc   \n",
      "2              $5000           $714454                      4moms   \n",
      "3              $1000           $194501      Backcountry Access EU   \n",
      "4              $2000           $261536         ICONIX BRAND Group   \n",
      "...              ...               ...                        ...   \n",
      "39701           $250            $33192                        NaN   \n",
      "39702           $250            $24299                     Toshio   \n",
      "39703           $250            $24299                        NaN   \n",
      "39704           $100            $17015                        NaN   \n",
      "39705          $2000           $140360  Total Power Solutions Inc   \n",
      "\n",
      "                       Vertical          Tranco         Page Rank  \\\n",
      "0       Business And Industrial           26194           5690723   \n",
      "1       Business And Industrial           57803          19270643   \n",
      "2      Technology And Computing           61764            635335   \n",
      "3      Technology And Computing           82130            605129   \n",
      "4             Style And Fashion           44533            346122   \n",
      "...                         ...             ...               ...   \n",
      "39701         Style And Fashion  Outside Top 1m          44866611   \n",
      "39702                       NaN  Outside Top 1m  Outside Top 100m   \n",
      "39703                       NaN  Outside Top 1m  Outside Top 100m   \n",
      "39704   Business And Industrial  Outside Top 1m  Outside Top 100m   \n",
      "39705   Automotive And Vehicles  Outside Top 1m          55490338   \n",
      "\n",
      "             Majestic        Umbrella  ...              City     State    Zip  \\\n",
      "0              590301  Outside Top 1m  ...           Burbank        CA  91504   \n",
      "1      Outside Top 1m  Outside Top 1m  ...          Longwood        FL  32750   \n",
      "2               93332  Outside Top 1m  ...        Pittsburgh        PA  15222   \n",
      "3              170557          191175  ...           Boulder  Colorado  80301   \n",
      "4               49422  Outside Top 1m  ...  Huntington Beach        CA  92649   \n",
      "...               ...             ...  ...               ...       ...    ...   \n",
      "39701  Outside Top 1m  Outside Top 1m  ...           Chicago        IL  60647   \n",
      "39702  Outside Top 1m  Outside Top 1m  ...            Kahuku        HI  96731   \n",
      "39703  Outside Top 1m  Outside Top 1m  ...               NaN       NaN    NaN   \n",
      "39704  Outside Top 1m  Outside Top 1m  ...        Wellington        FL  33414   \n",
      "39705  Outside Top 1m  Outside Top 1m  ...         Kingsport        TN    NaN   \n",
      "\n",
      "      Country First Detected  Last Found First Indexed Last Indexed Exclusion  \\\n",
      "0          US     2015-10-12  2021-08-02    2011-01-03   2021-08-02         -   \n",
      "1          US     2019-02-03  2021-08-03    2013-05-21   2021-08-03         -   \n",
      "2          US     2015-05-05  2021-07-25    2003-09-25   2021-08-02         -   \n",
      "3          US     2021-01-21  2021-06-12    2013-01-31   2021-07-31         -   \n",
      "4          US     2019-05-11  2021-08-02    2011-01-03   2021-08-02         -   \n",
      "...       ...            ...         ...           ...          ...       ...   \n",
      "39701      US     2016-07-28  2021-07-31    2013-01-31   2021-07-31         -   \n",
      "39702      US     2013-12-15  2021-06-07    2013-02-28   2021-06-07         -   \n",
      "39703     NaN     2021-07-20  2021-07-30    2021-07-20   2021-08-03         -   \n",
      "39704      US     2020-12-14  2021-07-30    2017-07-29   2021-07-30         -   \n",
      "39705      US     2016-12-27  2021-07-30    2015-11-25   2021-07-30         -   \n",
      "\n",
      "            Compliance  \n",
      "0      California CCPA  \n",
      "1                    -  \n",
      "2                    -  \n",
      "3                    -  \n",
      "4      California CCPA  \n",
      "...                ...  \n",
      "39701                -  \n",
      "39702                -  \n",
      "39703                -  \n",
      "39704                -  \n",
      "39705                -  \n",
      "\n",
      "[39706 rows x 34 columns]\n"
     ]
    }
   ],
   "source": [
    "print(mydata0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09cc75bc-42ac-466b-b277-9ddf7c9cd97b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of column names :  ['Domain', 'Location on Site', 'Tech Spend USD', 'Sales Revenue USD', 'Company', 'Vertical', 'Tranco', 'Page Rank', 'Majestic', 'Umbrella', 'Telephones', 'Emails', 'Twitter', 'Facebook', 'LinkedIn', 'Google', 'Pinterest', 'GitHub', 'Instagram', 'Vk', 'Vimeo', 'Youtube', 'TikTok', 'People', 'City', 'State', 'Zip', 'Country', 'First Detected', 'Last Found', 'First Indexed', 'Last Indexed', 'Exclusion', 'Compliance']\n"
     ]
    }
   ],
   "source": [
    " \n",
    "# creating a list of column names by\n",
    "# calling the .columns\n",
    "list_of_column_names = list(mydata0.columns)\n",
    " \n",
    "# displaying the list of column names\n",
    "print('List of column names : ',\n",
    "      list_of_column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0acc949-40ed-48b1-a4fb-e14889d6bb05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Business And Industrial' 'Technology And Computing' 'Style And Fashion'\n",
      " 'Sports' 'Art And Entertainment' 'Home And Garden'\n",
      " 'Automotive And Vehicles' 'Education' 'Food And Drink' 'Shopping' nan\n",
      " 'Health And Fitness' 'Careers' 'Law  Govt And Politics' 'Science'\n",
      " 'Hobbies And Interests' 'Travel' 'Religion And Spirituality' 'Finance'\n",
      " 'Real Estate' 'Family And Parenting' 'Pets' 'Society' 'Adult']\n",
      "24\n"
     ]
    }
   ],
   "source": [
    "#sorting\n",
    "a = mydata0['Vertical'].unique()\n",
    "print(a)\n",
    "print(len(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "751da626-c100-44f9-92a5-5fdcf263c315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Business And Industrial      6327\n",
      "Style And Fashion            6155\n",
      "Technology And Computing     3674\n",
      "Food And Drink               2660\n",
      "Automotive And Vehicles      2513\n",
      "Art And Entertainment        2394\n",
      "Home And Garden              1646\n",
      "Sports                       1452\n",
      "Shopping                     1145\n",
      "Health And Fitness            864\n",
      "Law  Govt And Politics        862\n",
      "Hobbies And Interests         715\n",
      "Science                       491\n",
      "Travel                        471\n",
      "Education                     400\n",
      "Finance                       339\n",
      "Pets                          209\n",
      "Society                       121\n",
      "Family And Parenting           98\n",
      "Real Estate                    92\n",
      "Adult                          63\n",
      "Religion And Spirituality      30\n",
      "Careers                        30\n",
      "Name: Vertical, dtype: int64\n",
      "total:  23\n"
     ]
    }
   ],
   "source": [
    "allver= mydata0['Vertical'].value_counts();\n",
    "print(allver)\n",
    "total_ver = len(mydata0['Vertical'].value_counts())\n",
    "print('total: ',total_ver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d0916e34-d0b3-4775-b00e-f431bbdbf8af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from ['Business And Industrial' nan 'Technology And Computing'\n",
      " 'Art And Entertainment' 'Science' 'Law  Govt And Politics' 'Finance'\n",
      " 'Travel' 'Health And Fitness' 'Education' 'Automotive And Vehicles'\n",
      " 'Society' 'Family And Parenting' 'Sports' 'Hobbies And Interests'\n",
      " 'Careers' 'Real Estate' 'Style And Fashion' 'Pets' 'Shopping'\n",
      " 'Food And Drink' 'Religion And Spirituality' 'Adult' 'Home And Garden'\n",
      " 'News']\n",
      "trying :  Business And Industrial\n",
      "Business And Industrial.csv\n",
      "saved\n",
      "trying :  Technology And Computing\n",
      "Technology And Computing.csv\n",
      "saved\n",
      "trying :  Art And Entertainment\n",
      "Art And Entertainment.csv\n",
      "saved\n",
      "trying :  Science\n",
      "Science.csv\n",
      "saved\n",
      "trying :  Law  Govt And Politics\n",
      "Law  Govt And Politics.csv\n",
      "saved\n",
      "trying :  Finance\n",
      "Finance.csv\n",
      "saved\n",
      "trying :  Travel\n",
      "Travel.csv\n",
      "saved\n",
      "trying :  Health And Fitness\n",
      "Health And Fitness.csv\n",
      "saved\n",
      "trying :  Education\n",
      "Education.csv\n",
      "saved\n",
      "trying :  Automotive And Vehicles\n",
      "Automotive And Vehicles.csv\n",
      "saved\n",
      "trying :  Society\n",
      "Society.csv\n",
      "saved\n",
      "trying :  Family And Parenting\n",
      "Family And Parenting.csv\n",
      "saved\n",
      "trying :  Sports\n",
      "Sports.csv\n",
      "saved\n",
      "trying :  Hobbies And Interests\n",
      "Hobbies And Interests.csv\n",
      "saved\n",
      "trying :  Careers\n",
      "Careers.csv\n",
      "saved\n",
      "trying :  Real Estate\n",
      "Real Estate.csv\n",
      "saved\n",
      "trying :  Style And Fashion\n",
      "Style And Fashion.csv\n",
      "saved\n",
      "trying :  Pets\n",
      "Pets.csv\n",
      "saved\n",
      "trying :  Shopping\n",
      "Shopping.csv\n",
      "saved\n",
      "trying :  Food And Drink\n",
      "Food And Drink.csv\n",
      "saved\n",
      "trying :  Religion And Spirituality\n",
      "Religion And Spirituality.csv\n",
      "saved\n",
      "trying :  Adult\n",
      "Adult.csv\n",
      "saved\n",
      "trying :  Home And Garden\n",
      "Home And Garden.csv\n",
      "saved\n",
      "trying :  News\n",
      "News.csv\n",
      "saved\n"
     ]
    }
   ],
   "source": [
    "##DONOT RUN THIS###\n",
    "import numpy as np\n",
    "print('from' ,a)\n",
    "for x in a:\n",
    "    if(pd.isna(x) == 0):\n",
    "        print('Running : ',x )\n",
    "        print(x+'.csv')\n",
    "        newval = mydata0[mydata0['Vertical'] == x].to_csv(x+'.csv')\n",
    "        #csv file name to be read in\n",
    "        in_csv = x+'.csv'\n",
    "\n",
    "        #get the number of lines of the csv file to be read\n",
    "        number_lines = sum(1 for row in (open(in_csv)))\n",
    "\n",
    "        #size of rows of data to write to the csv,\n",
    "\n",
    "        #you can change the row size according to your need\n",
    "        rowsize = 5000\n",
    "\n",
    "        #start looping through data writing it to a new file for each set\n",
    "        for i in range(0,number_lines,rowsize):\n",
    "\n",
    "            newdf = pd.read_csv(in_csv,\n",
    "                  nrows = rowsize,#number of rows to read at each loop\n",
    "                  skiprows = i)#skip rows that have been read\n",
    "\n",
    "            #csv to write data to a new file with indexed name. input_1.csv etc.\n",
    "            out_csv = x + str(i) + '.csv'\n",
    "\n",
    "            newdf.to_csv(out_csv,\n",
    "                  index=True,\n",
    "                  header=False,\n",
    "                  mode='a',#append data to csv file\n",
    "                  chunksize=rowsize)#size of data to append for each l\n",
    "        print('saved')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0eadba21-0435-4ff9-8bbb-b920a0bac6bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from ['Business And Industrial' 'Technology And Computing' 'Style And Fashion'\n",
      " 'Sports' 'Art And Entertainment' 'Home And Garden'\n",
      " 'Automotive And Vehicles' 'Education' 'Food And Drink' 'Shopping' nan\n",
      " 'Health And Fitness' 'Careers' 'Law  Govt And Politics' 'Science'\n",
      " 'Hobbies And Interests' 'Travel' 'Religion And Spirituality' 'Finance'\n",
      " 'Real Estate' 'Family And Parenting' 'Pets' 'Society' 'Adult']\n",
      "trying :  Business And Industrial\n",
      "Business And Industrial.csv\n",
      "DONE splitting Business And Industrial into 2 files\n",
      "DONE splitting Business And Industrial into 2 files\n",
      "saved\n",
      "trying :  Technology And Computing\n",
      "Technology And Computing.csv\n",
      "DONE splitting Technology And Computing into 1 files\n",
      "saved\n",
      "trying :  Style And Fashion\n",
      "Style And Fashion.csv\n",
      "DONE splitting Style And Fashion into 2 files\n",
      "DONE splitting Style And Fashion into 2 files\n",
      "saved\n",
      "trying :  Sports\n",
      "Sports.csv\n",
      "DONE splitting Sports into 1 files\n",
      "saved\n",
      "trying :  Art And Entertainment\n",
      "Art And Entertainment.csv\n",
      "DONE splitting Art And Entertainment into 1 files\n",
      "saved\n",
      "trying :  Home And Garden\n",
      "Home And Garden.csv\n",
      "DONE splitting Home And Garden into 1 files\n",
      "saved\n",
      "trying :  Automotive And Vehicles\n",
      "Automotive And Vehicles.csv\n",
      "DONE splitting Automotive And Vehicles into 1 files\n",
      "saved\n",
      "trying :  Education\n",
      "Education.csv\n",
      "DONE splitting Education into 1 files\n",
      "saved\n",
      "trying :  Food And Drink\n",
      "Food And Drink.csv\n",
      "DONE splitting Food And Drink into 1 files\n",
      "saved\n",
      "trying :  Shopping\n",
      "Shopping.csv\n",
      "DONE splitting Shopping into 1 files\n",
      "saved\n",
      "trying :  Health And Fitness\n",
      "Health And Fitness.csv\n",
      "DONE splitting Health And Fitness into 1 files\n",
      "saved\n",
      "trying :  Careers\n",
      "Careers.csv\n",
      "DONE splitting Careers into 1 files\n",
      "saved\n",
      "trying :  Law  Govt And Politics\n",
      "Law  Govt And Politics.csv\n",
      "DONE splitting Law  Govt And Politics into 1 files\n",
      "saved\n",
      "trying :  Science\n",
      "Science.csv\n",
      "DONE splitting Science into 1 files\n",
      "saved\n",
      "trying :  Hobbies And Interests\n",
      "Hobbies And Interests.csv\n",
      "DONE splitting Hobbies And Interests into 1 files\n",
      "saved\n",
      "trying :  Travel\n",
      "Travel.csv\n",
      "DONE splitting Travel into 1 files\n",
      "saved\n",
      "trying :  Religion And Spirituality\n",
      "Religion And Spirituality.csv\n",
      "DONE splitting Religion And Spirituality into 1 files\n",
      "saved\n",
      "trying :  Finance\n",
      "Finance.csv\n",
      "DONE splitting Finance into 1 files\n",
      "saved\n",
      "trying :  Real Estate\n",
      "Real Estate.csv\n",
      "DONE splitting Real Estate into 1 files\n",
      "saved\n",
      "trying :  Family And Parenting\n",
      "Family And Parenting.csv\n",
      "DONE splitting Family And Parenting into 1 files\n",
      "saved\n",
      "trying :  Pets\n",
      "Pets.csv\n",
      "DONE splitting Pets into 1 files\n",
      "saved\n",
      "trying :  Society\n",
      "Society.csv\n",
      "DONE splitting Society into 1 files\n",
      "saved\n",
      "trying :  Adult\n",
      "Adult.csv\n",
      "DONE splitting Adult into 1 files\n",
      "saved\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import sys\n",
    "import os\n",
    "print('from' ,a)\n",
    "for x in a:\n",
    "    if(pd.isna(x) == 0):\n",
    "        print('Running : ',x )\n",
    "        print(x+'.csv')\n",
    "        newval = mydata0[mydata0['Vertical'] == x].to_csv(x+'.csv')\n",
    "        filename = x+'.csv'\n",
    "\n",
    "        rows_per_csv = 5000\n",
    "\n",
    "        with open(filename) as infile:\n",
    "            reader = csv.DictReader(infile)\n",
    "            header = reader.fieldnames\n",
    "            rows = [row for row in reader]\n",
    "            pages = []\n",
    "\n",
    "            row_count = len(rows)\n",
    "            start_index = 0\n",
    "            # here, we slice the total rows into pages, each page having [row_per_csv] rows\n",
    "            while start_index < row_count:\n",
    "                pages.append(rows[start_index: start_index+rows_per_csv])\n",
    "                start_index += rows_per_csv\n",
    "\n",
    "            for i, page in enumerate(pages):\n",
    "                with open('{}_{}.csv'.format(x, i+1), 'w+') as outfile:\n",
    "                    writer = csv.DictWriter(outfile, fieldnames=header)\n",
    "                    writer.writeheader()\n",
    "                    for row in page:\n",
    "                        writer.writerow(row)\n",
    "\n",
    "                print('DONE splitting {} into {} files'.format(x, len(pages)))\n",
    "        print('saved')\n",
    "        os.remove(x+'.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d186c7dc-0cef-42e0-802a-5eba8980c308",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
